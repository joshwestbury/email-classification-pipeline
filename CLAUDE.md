# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

This project enhances a custom **Collection Notes** module in NetSuite by introducing AI-powered sentiment and intent analysis for inbound customer emails. The goal is to automatically analyze emails, categorize their sentiment and intent into a standardized taxonomy, extract key entities (dates, amounts, invoice IDs), and generate structured Collection Note records in NetSuite.

### Python Best Practices

- **Style:** Follow PEP 8 rigorously. Use Black for consistent formatting.
- **Type Hinting:** Use PEP 484 type annotations for all functions and class methods.
- **Docstrings:** Use Google-style docstrings for all public functions and classes.
- **Error Handling:** Implement robust error handling with custom exceptions where appropriate.
- **Testing:** Write comprehensive unit tests for all modules using `pytest`.
- **Dependency Management:** Use `uv` for dependency management and virtual environments. Never use `pip`.
- **Git:** When writing commit messages never inlcude anything like "Generated by Claude" in the commit message.

## Project Phases

### Phase 1: Taxonomy Discovery ✅ **COMPLETED**

**Goal**: Develop a preliminary, reusable taxonomy of sentiment and intent categories from ~1k real collection emails.

**Status**: Complete - All deliverables generated and refined for production use

**Key Accomplishments**:
- Successfully clustered 703 incoming emails into 24 distinct groups
- Generated preliminary categories using GPT-4o analysis of top 8 clusters
- Refined taxonomy through human curation into production-ready categories
- Created comprehensive labeling guide with examples and decision rules

**Final Taxonomy**:
- **3 Intent Categories**: Payment Inquiry, Invoice Management, Information Request
- **4 Sentiment Categories**: Cooperative, Administrative, Informational, Frustrated
- **Coverage**: 52.3% of emails from analyzed clusters
- **Business Value**: Clear actionable categories for NetSuite Collection Notes

**Deliverables**:

- `taxonomy_draft.json` — initial categories with examples ✅
- `taxonomy.yaml` — curated taxonomy with definitions and rules ✅
- `taxonomy_labeling_guide.md` — guide with examples and counterexamples ✅
- `cluster_analyses_llm.json` — detailed LLM analysis of email clusters ✅
- `master_email_threads_anonymized.json` — final processed dataset (5,693 emails) ✅

### Phase 2: Prototype Classifier **NEXT**

**Goal**: Build and validate an LLM-powered classifier that applies the taxonomy to real emails.

**Key Steps**:

1. Define strict JSON schema for structured outputs
2. Design few-shot prompts with system instructions
3. Manual labeling of 150-250 email subset for validation
4. Model performance testing (target ≥85% precision on top intents)
5. Iterate and refine based on confusion matrix analysis

**Deliverables**:

- `response_schema.json` — strict JSON schema for model output
- `emails_labeled.csv` — ground-truth labeled subset
- `confusion_matrix.png` — model vs human performance visualization
- `system_prompt.txt` — final prompt for production use

## Reusable Pipeline Architecture

The project now includes a modular pipeline system for processing multiple email datasets:

### Pipeline Components

- **`pipeline/`** — Modular components for reusable taxonomy discovery
- **`run_pipeline.py`** — CLI entry point for processing new datasets
- **`pipeline_config_template.yaml`** — Configuration template for new datasets
- **`PIPELINE_README.md`** — Usage documentation and examples

### Using the Pipeline

**Quick Start:**
```bash
# Create template configuration
python run_pipeline.py --create-template

# Process new email dataset
python run_pipeline.py --input new_emails.json --dataset-name customer_q4

# Use custom configuration
python run_pipeline.py --config my_dataset.yaml
```

**Pipeline Steps:**
1. Data processing (HTML cleaning, thread separation)
2. PII anonymization (emails, phones, addresses, names)
3. Embedding generation (sentence transformers)
4. Clustering analysis (UMAP + HDBSCAN)
5. LLM category proposal (GPT-4o analysis)

Each dataset gets organized outputs in `outputs/{dataset_name}/` for easy management.

## Data Structure

### Final Production Taxonomy (Phase 1 Results)

**Intent Categories:**
- **Payment Inquiry** — Questions about payment status, methods, or schedules
- **Invoice Management** — Requests for invoice details, corrections, or documentation
- **Information Request** — General information requests not related to payments/invoices

**Sentiment Categories:**
- **Cooperative** — Willing to work together, positive engagement
- **Administrative** — Neutral, business-focused communication
- **Informational** — Seeking or providing factual information
- **Frustrated** — Expressing dissatisfaction or impatience

**Coverage**: 52.3% of emails from analyzed clusters (367 out of 703 incoming emails)

*See `taxonomy.yaml` and `taxonomy_labeling_guide.md` for detailed definitions and examples.*

### Legacy Categories (Pre-Phase 1)

*These were preliminary examples from initial analysis - superseded by the production taxonomy above:*

- apologetic, dispute, in process, acknowledgement, unknown

### Expected Output Schema

The classifier will output structured JSON containing:

- `intent` (one value from taxonomy)
- `tone` (one value from sentiment set)
- `modifiers` (urgency, commitment strength, risk flags)
- `extracted_entities` (dates, amounts, invoice IDs)
- `rationale` (short natural language explanation)

### Collection Note Record Fields

- **Note Type field**: Automated (can't be edited in UI) or User Generated
- **Sentiment**: Picklist based on the taxonomy categories

## Dataset Information

### Original Sample Data
- `litera_raw_emails.json`: Original sample email data (4,697 emails)

### Processed Datasets
- `master_email_threads.json`: Separated email threads (5,693 individual emails)
- `master_email_threads_anonymized.json`: Final anonymized dataset for analysis
- `incoming_email_embeddings.npy`: Vector embeddings for 703 incoming emails
- `thread_context_embeddings.npy`: Context embeddings for 372 email threads

### Pipeline Outputs
When using the pipeline with new datasets, outputs are organized in:
```
outputs/{dataset_name}/
├── processed_emails.json     # Cleaned and structured
├── anonymized_emails.json    # PII-removed dataset
├── embeddings/              # Vector representations
├── cluster_results.json     # Clustering analysis
├── taxonomy_analysis.json   # LLM-proposed categories
└── pipeline_summary.json    # Run summary and metrics
```

## Development Workflow

When working on this project:

1. **For new datasets**: Use the pipeline system (`run_pipeline.py`) for consistent processing
2. **Phase 2 development**: Build on the completed Phase 1 taxonomy and deliverables
3. Ensure all sensitive data is properly anonymized during processing
4. Maintain version control for taxonomy files and prompts
5. Document model performance metrics and validation results
6. Prepare deliverables for eventual NetSuite User Event integration

### Pipeline Usage for New Datasets

```bash
# Quick start with new email dataset
python run_pipeline.py --input new_emails.json --dataset-name dataset_name

# Custom configuration approach
python run_pipeline.py --create-template
# Edit the generated template
python run_pipeline.py --config my_config.yaml
```

