# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

This project enhances a custom **Collection Notes** module in NetSuite by introducing AI-powered sentiment and intent analysis for inbound customer emails. The goal is to automatically analyze emails, categorize their sentiment and intent into a standardized taxonomy, extract key entities (dates, amounts, invoice IDs), and generate structured Collection Note records in NetSuite.

### Python Best Practices

- **Style:** Follow PEP 8 rigorously. Use Black for consistent formatting.
- **Type Hinting:** Use PEP 484 type annotations for all functions and class methods.
- **Docstrings:** Use Google-style docstrings for all public functions and classes.
- **Error Handling:** Implement robust error handling with custom exceptions where appropriate.
- **Testing:** Write comprehensive unit tests for all modules using `pytest`.
- **Dependency Management:** Use `uv` for dependency management and virtual environments. Never use `pip`.
- **Git:** When writing commit messages never inlcude anything like "Generated by Claude" in the commit message.

## Project Phases

### Phase 1: Taxonomy Discovery

**Goal**: Develop a preliminary, reusable taxonomy of sentiment and intent categories from ~1k real collection emails.

**Key Steps**:

1. Data preparation and anonymization of sensitive information
2. Generate embeddings and cluster emails using UMAP and HDBSCAN
3. Use LLM to propose category names, definitions, and decision rules
4. Human curation to ensure mutually exclusive categories (10-16 intents, 4-5 sentiments)

**Deliverables**:

- `taxonomy_draft.json` — initial categories with examples
- `taxonomy.yaml` — curated taxonomy with definitions and rules
- `taxonomy_labeling_guide.md` — guide with examples and counterexamples

### Phase 2: Prototype Classifier

**Goal**: Build and validate an LLM-powered classifier that applies the taxonomy to real emails.

**Key Steps**:

1. Define strict JSON schema for structured outputs
2. Design few-shot prompts with system instructions
3. Manual labeling of 150-250 email subset for validation
4. Model performance testing (target ≥85% precision on top intents)
5. Iterate and refine based on confusion matrix analysis

**Deliverables**:

- `response_schema.json` — strict JSON schema for model output
- `emails_labeled.csv` — ground-truth labeled subset
- `confusion_matrix.png` — model vs human performance visualization
- `system_prompt.txt` — final prompt for production use

## Data Structure

### Current Sentiment Categories - NOTE: these are merely examples and are not to be taken as standard or perminent.

Based on initial analysis (from `CollectionNotes_SentimentAnalysis.txt`):

- **apologetic** — customer expresses regret or apology
- **dispute**
  - incorrect information (name, address, tax, amount, product, terms)
  - unsatisfied (service issue, product issue)
- **in process**
  - pending approval
  - pending payment
- **acknowledgement** — customer confirms receipt of communication
- **unknown** — unclear or insufficient information to categorize

### Expected Output Schema

The classifier will output structured JSON containing:

- `intent` (one value from taxonomy)
- `tone` (one value from sentiment set)
- `modifiers` (urgency, commitment strength, risk flags)
- `extracted_entities` (dates, amounts, invoice IDs)
- `rationale` (short natural language explanation)

### Collection Note Record Fields

- **Note Type field**: Automated (can't be edited in UI) or User Generated
- **Sentiment**: Picklist based on the taxonomy categories

## Sample Data

- `CollectionNotes_SentimentAnalysis_SampleEmails.json`: Contains sample email data with IDs, subjects, and HTML message content for sentiment analysis training/testing
- Each email record includes an ID, subject line, and full HTML message content from real collection correspondence

## Development Workflow

When working on this project:

1. Follow the phase-based approach outlined in `project_plan.md`
2. Ensure all sensitive data is properly anonymized during processing
3. Maintain version control for taxonomy files and prompts
4. Document model performance metrics and validation results
5. Prepare deliverables for eventual NetSuite User Event integration

